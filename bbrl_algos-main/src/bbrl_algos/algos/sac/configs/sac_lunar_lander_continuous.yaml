save_best: True
plot_agents: True

log_dir: ./tmp
video_dir: ${log_dir}/videos

hydra:
  run:
    dir: ${log_dir}/hydra/${now:%Y-%m-%d}/${now:%H-%M-%S}

logger:
  classname: bbrl.utils.logger.TFLogger
  log_dir: ./ppo_logs/
  verbose: False
  every_n_seconds: 10

algorithm:
  seed:
    train: 1
    eval: 99
    q: 123
    explorer: 456
    torch: 7

  n_envs: 10
  n_steps_train: 50
  n_steps: 2_000_000
  eval_interval: 5000
  nb_evals: 10
  buffer_size: 1e6
  batch_size: 256
  learning_starts: 10000
  tau_target: 0.05
  max_grad_norm: 0.5
  discount_factor: 0.95
  entropy_mode: "auto" # "auto" or "fixed"
  init_entropy_coef: 2e-7
  actor_type: SquashedGaussianActor
  architecture:
    actor_hidden_size: [256, 256]
    critic_hidden_size: [512, 512]

gym_env:
  env_name: LunarLanderContinuous-v2

actor_optimizer:
  classname: torch.optim.Adam
  lr: 1e-3

critic_optimizer:
  classname: torch.optim.Adam
  lr: 1e-3

entropy_coef_optimizer:
  classname: torch.optim.Adam
  lr: 1e-3
