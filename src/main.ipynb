{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[easypip] Installing bbrl_gymnasium>=0.2.0\n",
      "[easypip] Installing bbrl_gymnasium[box2d]\n",
      "[easypip] Installing bbrl_gymnasium[classic_control]\n"
     ]
    }
   ],
   "source": [
    "from easypip import easyimport, easyinstall, is_notebook\n",
    "easyinstall(\"bbrl>=0.2.2\")\n",
    "easyinstall(\"swig\")\n",
    "easyinstall(\"bbrl_gymnasium>=0.2.0\")\n",
    "easyinstall(\"bbrl_gymnasium[box2d]\")\n",
    "easyinstall(\"bbrl_gymnasium[classic_control]\")\n",
    "easyinstall(\"tensorboard\")\n",
    "easyinstall(\"moviepy\")\n",
    "easyinstall(\"box2d-kengz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from moviepy.editor import ipython_display as video_display\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, Optional\n",
    "from functools import partial\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import bbrl_gymnasium\n",
    "\n",
    "import copy\n",
    "from abc import abstractmethod, ABC\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import strftime\n",
    "\n",
    "from gymnasium import Env, Space, Wrapper, make\n",
    "\n",
    "from bbrl.agents.agent import Agent\n",
    "from bbrl import get_arguments, get_class, instantiate_class\n",
    "from bbrl.workspace import Workspace\n",
    "from bbrl.agents import Agents, TemporalAgent\n",
    "from bbrl.agents.gymnasium import GymAgent, ParallelGymAgent, make_env, record_video\n",
    "from bbrl.utils.replay_buffer import ReplayBuffer\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Tuple\n",
    "from bbrl.agents.gymnasium import make_env, GymAgent, ParallelGymAgent\n",
    "from functools import partial\n",
    "\n",
    "from bbrl import instantiate_class\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "import random as python_random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for launching tensorboard\n",
    "# For Colab - otherwise, it is easier and better to launch tensorboard from\n",
    "# the terminal\n",
    "def setup_tensorboard(path):\n",
    "    path = Path(path)\n",
    "    answer = \"\"\n",
    "    if is_notebook():\n",
    "        if get_ipython().__class__.__module__ == \"google.colab._shell\":\n",
    "            answer = \"y\"\n",
    "        while answer not in [\"y\", \"n\"]:\n",
    "                answer = input(f\"Do you want to launch tensorboard in this notebook [y/n] \").lower()\n",
    "\n",
    "    if answer == \"y\":\n",
    "        get_ipython().run_line_magic(\"load_ext\", \"tensorboard\")\n",
    "        get_ipython().run_line_magic(\"tensorboard\", f\"--logdir {path.absolute()}\")\n",
    "    else:\n",
    "        import sys\n",
    "        import os\n",
    "        import os.path as osp\n",
    "        print(f\"Launch tensorboard from the shell:\\n{osp.dirname(sys.executable)}/tensorboard --logdir={path.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "params={\n",
    "  \"save_best\": False,\n",
    "  \"logger\":{\n",
    "    \"classname\": \"bbrl.utils.logger.TFLogger\",\n",
    "    \"log_dir\": \"./tblogs/dqn-buffer-\" + str(time.time()),\n",
    "    \"cache_size\": 10000,\n",
    "    \"every_n_seconds\": 10,\n",
    "    \"verbose\": False,    \n",
    "    },\n",
    "\n",
    "  \"algorithm\":{\n",
    "    \"seed\": SEED,\n",
    "    \"max_grad_norm\": 0.5,\n",
    "    \"epsilon\": 0.02,\n",
    "    \"n_envs\": 8,\n",
    "    \"n_steps\": 32,\n",
    "    \"n_updates\": 32,\n",
    "    \"eval_interval\": 2000,\n",
    "    \"learning_starts\": 2000,\n",
    "    \"nb_evals\": 10,\n",
    "    \"buffer_size\": 1e6,\n",
    "    \"batch_size\": 256,\n",
    "    \"target_critic_update\": 5000,\n",
    "    \"max_epochs\": 100, #MAX ITER \n",
    "    \"discount_factor\": 0.99,\n",
    "    \"architecture\":{\"hidden_size\": [64, 64]},\n",
    "  },\n",
    "  \"gym_env\":{\n",
    "    \"env_name\": \"CartPole-v1\",\n",
    "  },\n",
    "  \"optimizer\":\n",
    "  {\n",
    "    \"classname\": \"torch.optim.Adam\",\n",
    "    \"lr\": 1e-3,\n",
    "  }\n",
    "}\n",
    "\n",
    "config=OmegaConf.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    python_random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "class oldCnnAgent:\n",
    "    def __init__(self):\n",
    "        set_seeds(SEED) \n",
    "\n",
    "    def build_feature_extractor_model(self, input_shape):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (7, 7), strides=(2, 2), activation='relu', padding=\"same\", input_shape=(151, 562, 1)))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Conv2D(64, (7, 7), strides=(2, 2), padding=\"same\", activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Conv2D(64, (7, 7), strides=(2, 2), padding=\"same\", activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu')) #a changer la valeur ici pour la taille du ouput\n",
    "        return model\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        image_resized = np.expand_dims(np.expand_dims(image, axis=-1), axis=0)  \n",
    "        if not hasattr(self, 'model'):\n",
    "            self.model = self.build_feature_extractor_model(input_shape=image_resized.shape[1:])\n",
    "        features = self.model.predict(image_resized)\n",
    "        return features[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST AVEC UN RANDOM AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self, action_dim):\n",
    "        super().__init__()\n",
    "        self.action_dim = action_dim\n",
    "        self.all_observations = []\n",
    "\n",
    "    def forward(self, t: int, choose_action=True, **kwargs):\n",
    "        \"\"\"An Agent can use self.workspace\"\"\"\n",
    "        obs = self.get((\"env/env_obs\", t))\n",
    "        action = torch.randint(0, self.action_dim, (len(obs), ))\n",
    "        self.set((\"action\", t), action)\n",
    "        self.all_observations.append(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateCaptureAgent(Agent):\n",
    "    def __init__(self, storage_list):\n",
    "        super().__init__()\n",
    "        self.storage_list = storage_list  # This list will store the states\n",
    "\n",
    "    def forward(self, t: int, **kwargs):\n",
    "        # Retrieve the current state (observation) from the workspace\n",
    "        current_state = self.get((\"env/env_obs\", t))\n",
    "        # Append the current state to the storage list\n",
    "        self.storage_list.append(current_state)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomParallelGymAgent(ParallelGymAgent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def get_my_attribute(self):\n",
    "        # Replace 'my_attribute' with the actual attribute you're interested in\n",
    "        return self.envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeAccessAgent(Agent):\n",
    "    def __init__(self, env_agent, list_images, pre_processing_agent, cnn_agent):\n",
    "        super().__init__()\n",
    "        self.env_agent = env_agent  # CustomParallelGymAgent ou ParallelGymAgent\n",
    "        #init de la liste de listes pour store les images\n",
    "        self.list_images = [[] for _ in range(self.env_agent.num_envs)]\n",
    "        self.pre_processing_agent = pre_processing_agent\n",
    "        self.cnn_agent = cnn_agent\n",
    "        self.list_features = [[] for _ in range(self.env_agent.num_envs)]\n",
    "    \n",
    "    def forward(self, t: int, **kwargs):\n",
    "        for env_index in range(self.env_agent.num_envs):\n",
    "            # Assuming your env_agent can provide access to each environment's render method\n",
    "            image = self.env_agent.envs[env_index].render()\n",
    "            display = False\n",
    "            if display: #print a chaque temps l'image originale\n",
    "                clear_output(wait=True)  # pour print live mais pas utile pour +1 env\n",
    "                plt.imshow(image)  \n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                print(\"Displayed image at time\", t, \" of agent \", env_index)\n",
    "            #print(image.shape)\n",
    "            image_pre_processed = self.pre_processing_agent.preprocess(image)\n",
    "\n",
    "            # Append the image to the corresponding list\n",
    "            self.list_images[env_index].append(image_pre_processed)\n",
    "\n",
    "            # attention a bien mettre l'image preprocessed ici sinon y a des pb avec le cnn\n",
    "            features = self.cnn_agent.process_image(image_pre_processed) \n",
    "            #print(features.shape)\n",
    "            self.list_features[env_index].append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessingAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        # Assume image is a numpy array of shape (400, 600, 3)\n",
    "        # Convert to grayscale, resize, and ensure correct shape for CNN\n",
    "        processed_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
    "        processed_image = cv2.resize(processed_image, (224, 224))  # Resize to expected CNN input size\n",
    "        return processed_image #image de taille (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Convolution layer 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 16 x 112 x 112\n",
    "            \n",
    "            # Convolution layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 32 x 56 x 56\n",
    "            \n",
    "            # Convolution layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 64 x 28 x 28\n",
    "            \n",
    "            # Convolution layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 128 x 14 x 14\n",
    "            \n",
    "            # Convolution layer 5\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 256 x 7 x 7\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),  # The output feature vector size\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = CNN()  \n",
    "\n",
    "    def process_image(self, image):\n",
    "        # Convert a single preprocessed image to PyTorch tensor\n",
    "        image_tensor = torch.tensor(image, dtype=torch.float).unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, 224, 224]\n",
    "        image_tensor = image_tensor / 255.0  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = self.cnn(image_tensor)\n",
    "        return features.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImagesPerAgent(images_per_agent, nb_env):\n",
    "    n_cols = 3  # Number of columns in the grid\n",
    "    \n",
    "    for env_index, images in enumerate(images_per_agent):\n",
    "        print(f\"Environment {env_index + 1}:\")\n",
    "        n_images = len(images)\n",
    "        n_rows = (n_images + n_cols - 1) // n_cols  # Rows per environment\n",
    "\n",
    "        figsize_width = 10  # Adjust width as needed\n",
    "        figsize_height = n_rows * (figsize_width / n_cols) * 0.5  # Adjust height based on number of rows, keeping aspect ratio\n",
    "        plt.figure(figsize=(figsize_width, figsize_height))\n",
    "\n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(n_rows, n_cols, i+1)\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')  # Optional: to hide axes\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donzo got all images\n",
      "Environment 1:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x600 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_env = 1\n",
    "action_dim = 2 #vaudrait mieux prednre depuis le parallelgymagent mais ca va jamais changer ici\n",
    "#autoreset = False pour le moment pouor le simplifier la vie\n",
    "pre_processing_agent = PreProcessingAgent()\n",
    "cnn_agent = CNNAgent()\n",
    "\n",
    "im_env_agent = CustomParallelGymAgent(partial(make_env, config.gym_env.env_name, render_mode=\"rgb_array\", autoreset=False), nb_env).seed(SEED)\n",
    "attribute_access_agent = AttributeAccessAgent(im_env_agent, [], pre_processing_agent, cnn_agent)\n",
    "agents = Agents(im_env_agent, RandomAgent(action_dim), attribute_access_agent)\n",
    "t_agents = TemporalAgent(agents)\n",
    "\n",
    "workspace = Workspace()\n",
    "t_agents(workspace, t=0, stop_variable=\"env/done\", stochastic=True)\n",
    "images = attribute_access_agent.list_images #bon seul soucis c'est qu'on recupere les images apres coup\n",
    "print('Donzo got all images')\n",
    "displayImagesPerAgent(images, nb_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ON VA ESSAYER DE FAIRE UN AGENT DQN MAINTENANT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
