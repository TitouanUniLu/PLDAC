{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[easypip] Installing bbrl_gymnasium>=0.2.0\n",
      "[easypip] Installing bbrl_gymnasium[box2d]\n",
      "[easypip] Installing bbrl_gymnasium[classic_control]\n"
     ]
    }
   ],
   "source": [
    "from easypip import easyimport, easyinstall, is_notebook\n",
    "easyinstall(\"bbrl>=0.2.2\")\n",
    "easyinstall(\"swig\")\n",
    "easyinstall(\"bbrl_gymnasium>=0.2.0\")\n",
    "easyinstall(\"bbrl_gymnasium[box2d]\")\n",
    "easyinstall(\"bbrl_gymnasium[classic_control]\")\n",
    "easyinstall(\"tensorboard\")\n",
    "easyinstall(\"moviepy\")\n",
    "easyinstall(\"box2d-kengz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from moviepy.editor import ipython_display as video_display\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, Optional\n",
    "from functools import partial\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import bbrl_gymnasium\n",
    "\n",
    "import copy\n",
    "from abc import abstractmethod, ABC\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import strftime\n",
    "\n",
    "from gymnasium import Env, Space, Wrapper, make\n",
    "\n",
    "# Imports all the necessary classes and functions from BBRL\n",
    "from bbrl.agents.agent import Agent\n",
    "from bbrl import get_arguments, get_class, instantiate_class\n",
    "# The workspace is the main class in BBRL, this is where all data is collected and stored\n",
    "from bbrl.workspace import Workspace\n",
    "\n",
    "# Agents(agent1,agent2,agent3,...) executes the different agents the one after the other\n",
    "# TemporalAgent(agent) executes an agent over multiple timesteps in the workspace, \n",
    "# or until a given condition is reached\n",
    "from bbrl.agents import Agents, TemporalAgent\n",
    "\n",
    "# ParallelGymAgent is an agent able to execute a batch of gymnasium environments\n",
    "# with auto-resetting. These agents produce multiple variables in the workspace:\n",
    "# ’env/env_obs’, ’env/reward’, ’env/timestep’, ’env/terminated’,\n",
    "# 'env/truncated', 'env/done', ’env/cumulated_reward’, ... \n",
    "# \n",
    "# When called at timestep t=0, the environments are automatically reset. At\n",
    "# timestep t>0, these agents will read the ’action’ variable in the workspace at\n",
    "# time t − 1\n",
    "from bbrl.agents.gymnasium import GymAgent, ParallelGymAgent, make_env, record_video\n",
    "\n",
    "# Replay buffers are useful to store past transitions when training\n",
    "from bbrl.utils.replay_buffer import ReplayBuffer\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Tuple\n",
    "from bbrl.agents.gymnasium import make_env, GymAgent, ParallelGymAgent\n",
    "from functools import partial\n",
    "\n",
    "from bbrl import instantiate_class\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for launching tensorboard\n",
    "# For Colab - otherwise, it is easier and better to launch tensorboard from\n",
    "# the terminal\n",
    "def setup_tensorboard(path):\n",
    "    path = Path(path)\n",
    "    answer = \"\"\n",
    "    if is_notebook():\n",
    "        if get_ipython().__class__.__module__ == \"google.colab._shell\":\n",
    "            answer = \"y\"\n",
    "        while answer not in [\"y\", \"n\"]:\n",
    "                answer = input(f\"Do you want to launch tensorboard in this notebook [y/n] \").lower()\n",
    "\n",
    "    if answer == \"y\":\n",
    "        get_ipython().run_line_magic(\"load_ext\", \"tensorboard\")\n",
    "        get_ipython().run_line_magic(\"tensorboard\", f\"--logdir {path.absolute()}\")\n",
    "    else:\n",
    "        import sys\n",
    "        import os\n",
    "        import os.path as osp\n",
    "        print(f\"Launch tensorboard from the shell:\\n{osp.dirname(sys.executable)}/tensorboard --logdir={path.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "import numpy as np\n",
    "import random as python_random\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    python_random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "class cnnAgent:\n",
    "    def __init__(self):\n",
    "        set_seeds(SEED) \n",
    "\n",
    "    def build_feature_extractor_model(self, input_shape):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (7, 7), strides=(2, 2), activation='relu', padding=\"same\", input_shape=(151, 562, 1)))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Conv2D(64, (7, 7), strides=(2, 2), padding=\"same\", activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Conv2D(64, (7, 7), strides=(2, 2), padding=\"same\", activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu')) #a changer la valeur ici pour la taille du ouput\n",
    "        return model\n",
    "\n",
    "    def extract_features(self, image):\n",
    "        image_resized = np.expand_dims(np.expand_dims(image, axis=-1), axis=0)  \n",
    "        if not hasattr(self, 'model'):\n",
    "            self.model = self.build_feature_extractor_model(input_shape=image_resized.shape[1:])\n",
    "        features = self.model.predict(image_resized)\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "  \"save_best\": False,\n",
    "  \"logger\":{\n",
    "    \"classname\": \"bbrl.utils.logger.TFLogger\",\n",
    "    \"log_dir\": \"./tblogs/dqn-buffer-\" + str(time.time()),\n",
    "    \"cache_size\": 10000,\n",
    "    \"every_n_seconds\": 10,\n",
    "    \"verbose\": False,    \n",
    "    },\n",
    "\n",
    "  \"algorithm\":{\n",
    "    \"seed\": 4,\n",
    "    \"max_grad_norm\": 0.5,\n",
    "    \"epsilon\": 0.02,\n",
    "    \"n_envs\": 8,\n",
    "    \"n_steps\": 32,\n",
    "    \"n_updates\": 32,\n",
    "    \"eval_interval\": 2000,\n",
    "    \"learning_starts\": 2000,\n",
    "    \"nb_evals\": 10,\n",
    "    \"buffer_size\": 1e6,\n",
    "    \"batch_size\": 256,\n",
    "    \"target_critic_update\": 5000,\n",
    "    \"max_epochs\": 3500,\n",
    "    \"discount_factor\": 0.99,\n",
    "    \"architecture\":{\"hidden_size\": [64, 64]},\n",
    "  },\n",
    "  \"gym_env\":{\n",
    "    \"env_name\": \"CartPole-v1\",\n",
    "  },\n",
    "  \"optimizer\":\n",
    "  {\n",
    "    \"classname\": \"torch.optim.Adam\",\n",
    "    \"lr\": 1e-3,\n",
    "  }\n",
    "}\n",
    "\n",
    "config=OmegaConf.create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class preProcessingAgent():\n",
    "    def __init__(self, parallel_gym_agent):\n",
    "          self.parallel_gym_agent = parallel_gym_agent\n",
    "\n",
    "    def preProcess(self, im):\n",
    "        #plt.imshow(im) #CHANGE HERE TO SEE ORIGINAL FRAME\n",
    "        #plt.show()\n",
    "        img = Image.fromarray(im.astype(np.uint8))\n",
    "        img_gray = img.convert('L')\n",
    "        img_gray = img_gray.resize((564, 152)) #a modifier peut etre im.shape[1], im.shape[0])\n",
    "        img_array = np.array(img_gray)\n",
    "\n",
    "        return img_array\n",
    "\n",
    "    def crop(self, im):\n",
    "        im = Image.fromarray(im.astype(np.uint8))\n",
    "        width, height = im.size\n",
    "    \n",
    "        new_width, new_height = 300, 300  # New dimensions for the crop\n",
    "        left = (width - new_width)/8\n",
    "        top = (height - new_height)/0.6\n",
    "        right = (width + new_width)/1.5\n",
    "        bottom = (height + new_height)/2.2\n",
    "        \n",
    "        im1 = im.crop((left, top, right, bottom))\n",
    "        img_array = np.array(im1)\n",
    "        return img_array\n",
    "\n",
    "    def getFrame(self, env_agent):\n",
    "        env: Env = env_agent.envs[0]\n",
    "        env.reset()\n",
    "        im = env.render()\n",
    "        im = self.crop(im)\n",
    "        im = self.preProcess(im)\n",
    "        return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: observation space in R^4 and action space R^2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Extracted features shape: (1, 100)\n",
      "Extracted features array: [[13.333378   7.3049126 15.397407   0.         0.        13.111646\n",
      "  30.365862   0.        13.297258   0.        14.468754   0.\n",
      "   6.0612283  6.068844   0.        39.76304   30.016796   0.\n",
      "   0.        17.8886    53.121674   7.5338078  0.         0.\n",
      "   0.         0.         0.         0.         0.7277671  4.0468173\n",
      "  23.475471   0.        13.946899   7.6253715 34.12345    0.\n",
      "  16.004932   0.        36.293198   0.         0.         0.\n",
      "   0.        11.083226   0.         0.         0.         7.071604\n",
      "  25.153004   0.         9.039755   0.         0.         9.877197\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "  22.020353   0.         0.         0.        22.48362   21.370718\n",
      "  14.048566   4.2527947  0.        15.578289   0.        20.95405\n",
      "   0.         0.         6.7438984  0.        35.75955    0.\n",
      "  16.188839   3.309288   0.        16.967701   0.         0.\n",
      "  57.225452   0.         0.         7.7396226 20.921179   2.4856505\n",
      "  20.63118   36.48363   21.842888  27.75667    0.         0.\n",
      "  15.403627   0.         2.3619242 12.518244 ]]\n"
     ]
    }
   ],
   "source": [
    "env_agent = ParallelGymAgent(partial(make_env, config.gym_env.env_name, render_mode=\"rgb_array\"), 1).seed(SEED) #le int a la fin indique le nombre d'environements\n",
    "obs_size, action_dim = env_agent.get_obs_and_actions_sizes()\n",
    "print(f\"Environment: observation space in R^{obs_size} and action space R^{action_dim}\")\n",
    "\n",
    "preProc = preProcessingAgent(env_agent) # agent qui fait le pre processing\n",
    "\n",
    "\n",
    "im = preProc.getFrame(env_agent) #on recupere l'image\n",
    "\n",
    "\n",
    "feature_extractor = cnnAgent()\n",
    "features = feature_extractor.extract_features(im) #est ce qu'on filtre les 0 pour des raisons de simplicite??\n",
    "print(\"Extracted features shape:\", features.shape)\n",
    "print(\"Extracted features array:\", features)\n",
    "\n",
    "# en fait si on filtre les 0 on retrouve pas un array tt le temps de la meme taille, ca varie entre (1,50) et (1,52) en general (a voir...)\n",
    "#non_zero_mask = features != 0\n",
    "#filtered_features = features[non_zero_mask]\n",
    "#print(\"Filtered features shape:\", filtered_features.shape)\n",
    "#print(\"Filtered features array:\", filtered_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
